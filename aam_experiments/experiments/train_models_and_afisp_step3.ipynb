{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'nature', 'no-latex'])\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, average_precision_score, auc, brier_score_loss\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load main dataset\n",
    "aam_df = pd.read_hdf('/data/adarsh/fda_project_data/aam_model_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define trauma level based on hospital\n",
    "# hospitals not listed don't have \n",
    "aam_df['trauma_level'] = aam_df.hospital_jhh * 1 + aam_df.hospital_sh * 2 + aam_df.hospital_bmc * 2 + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commorbidity_df = pd.read_csv(\"/data/adarsh/fda_project_data/study_cohort_commorbidity_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > 500 beds\n",
    "aam_df['hospital_size_large'] = aam_df.hospital_jhh * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets based on hospital\n",
    "hospital_ids = ['hospital_bmc', \"hospital_hcgh\", \"hospital_jhh\", \"hospital_smh\", \"hospital_sh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train/test splits by hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make encounter level dataset\n",
    "pos_ids = aam_df.query('label == 1').enc_id.unique()\n",
    "all_ids = aam_df.enc_id.unique()\n",
    "neg_ids = np.array(list(set(all_ids).difference(set(pos_ids))))\n",
    "\n",
    "event_rows = aam_df.query('enc_id in @pos_ids').groupby('enc_id', as_index=False).nth(0)\n",
    "non_event_rows = aam_df.query('enc_id in @neg_ids').groupby('enc_id', as_index=False).nth(-1)\n",
    "aam_df = pd.concat([event_rows, non_event_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aam_df.sex.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a train and test set from each hospital\n",
    "hospital_df_dict = {}\n",
    "test_frac = 0.2\n",
    "\n",
    "\n",
    "for hospital_id in hospital_ids:\n",
    "    hospital_df = aam_df.query(hospital_id + ' == 1')\n",
    "    \n",
    "    enc_ids = hospital_df.enc_id.unique()\n",
    "    train_ids, test_ids = train_test_split(enc_ids, shuffle=True, test_size=test_frac, random_state=1234)\n",
    "    \n",
    "    hospital_train = hospital_df.query('enc_id in @train_ids')\n",
    "    hospital_test = hospital_df.query('enc_id in @test_ids')\n",
    "    \n",
    "    hospital_df_dict[hospital_id + '_train'] = hospital_train\n",
    "    hospital_df_dict[hospital_id + '_test'] = hospital_test\n",
    "    \n",
    "    print(\"Processed {}\".format(hospital_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models for each hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale continuous features so logistic regression and regularization behave well\n",
    "\n",
    "continuous_features = ['anion_gap', 'bicarbonate_sq', 'glucose',\n",
    "       'hematocrit_cu', 'lactate', 'bun_log', 'creatinine_log_sq', 'sodium',\n",
    "       'troponin', 'wbc', 'nbp_dias_latest_sq','nbp_sys_instability', 'nbp_sys_latest_cu', 'heart_rate_latest_cu',\n",
    "       'heart_rate_instability_log_sq', 'spo2_instability_log',\n",
    "       'spo2_latest_logit_cu', 'spo2_worst_logit', 'resp_rate_instability_log',\n",
    "       'temperature_instability_log_sq', 'temperature_latest_sq',\n",
    "       'resp_rate_latest_cu', 'resp_rate_worst', 'gcs_latest',\n",
    "       'anion_gap_bicarbonate_ratio', 'shock_index', 'los_log', 'age_log']\n",
    "discrete_features = ['troponin_missing', 'sex', 'season_1', 'season_2', 'season_3', 'time_of_day_1',\n",
    "       'time_of_day_2', 'time_of_day_3', 'ed_admit']# , \n",
    "                     # 'hospital_bmc','hospital_hcgh', 'hospital_jhh', 'hospital_sh', 'hospital_smh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = ['nbp_sys_instability', 'nbp_sys_latest_cu', 'heart_rate_latest_cu',\n",
    "       'heart_rate_instability_log_sq', 'spo2_instability_log',\n",
    "       'spo2_latest_logit_cu', 'spo2_worst_logit', 'resp_rate_instability_log',\n",
    "       'temperature_instability_log_sq', 'temperature_latest_sq',\n",
    "       'resp_rate_latest_cu', 'resp_rate_worst', 'gcs_latest', 'age_log', 'sex']\n",
    "\n",
    "# news_proxy_features = ['resp_rate_worst', 'spo2_worst_logit', 'temperature_latest_sq', 'nbp_sys_latest_cu', \n",
    "#                        'heart_rate_latest_cu', 'gcs_latest']\n",
    "\n",
    "# baseline_features = news_proxy_features + ['age_log', 'sex']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baseline_features), len(continuous_features + discrete_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models for each hospital\n",
    "import flaml.default\n",
    "\n",
    "# gbm = flaml.default.LGBMClassifier()\n",
    "hospital_models = {}\n",
    "hospital_scalers = {}\n",
    "\n",
    "hospital_baseline_models = {}\n",
    "\n",
    "for hospital in tqdm(hospital_ids):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    \n",
    "    train_df = hospital_df_dict[hospital + '_train'].copy()\n",
    "    \n",
    "    scaler.fit(train_df[continuous_features])\n",
    "    train_df[continuous_features] = scaler.transform(train_df[continuous_features])\n",
    "    train_X = train_df[continuous_features + discrete_features].values\n",
    "    train_y = train_df.label.values\n",
    "    \n",
    "#     lgbm = lgb.LGBMClassifier(n_estimators=200, num_leaves=139, min_child_samples=8, learning_rate=0.05, verbose=10)\n",
    "#     # hyperparams, estimator_name, X_trans, y_trans = gbm.suggest_hyperparams(train_X, train_y)\n",
    "#     lgbm.fit(train_X, train_y, verbose=10)\n",
    "    lgbm = LogisticRegression(random_state=1234, n_jobs=-1, verbose=10, C=1e3)\n",
    "    lgbm.fit(train_X, train_y)\n",
    "    \n",
    "    # baseline = LogisticRegression(random_state=1234, n_jobs=-1, C=1e3)\n",
    "    \n",
    "    baseline = lgb.LGBMClassifier(n_estimators=200, num_leaves=139, min_child_samples=8, learning_rate=0.05, verbose=10)\n",
    "    # hyperparams, estimator_name, X_trans, y_trans = gbm.suggest_hyperparams(train_X, train_y)\n",
    "    baseline.fit(train_df[baseline_features].values, train_y, verbose=10)\n",
    "    # baseline.fit(train_df[baseline_features].values, train_y)\n",
    "    \n",
    "    hospital_models[hospital] = lgbm\n",
    "    hospital_scalers[hospital] = scaler\n",
    "    hospital_baseline_models[hospital] = baseline\n",
    "    print(\"Training {} done\".format(hospital))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each model, make predictons on all test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test labels\n",
    "hospital_test_y = {}\n",
    "\n",
    "for hospital in hospital_ids:\n",
    "    test_df = hospital_df_dict[hospital + '_test']\n",
    "    test_y = test_df.label.values\n",
    "    \n",
    "    hospital_test_y[hospital] = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test_predictions\n",
    "hospital_test_preds = {}\n",
    "hospital_baseline_test_preds = {}\n",
    "auroc_dict = {}\n",
    "auprc_dict = {}\n",
    "\n",
    "auroc_baseline_dict = {}\n",
    "auprc_baseline_dict = {}\n",
    "\n",
    "for model_hospital in hospital_ids:\n",
    "    model = hospital_models[model_hospital]\n",
    "    \n",
    "    baseline_model = hospital_baseline_models[model_hospital]\n",
    "    \n",
    "    scaler = hospital_scalers[model_hospital]\n",
    "    for test_hospital in hospital_ids:\n",
    "        \n",
    "        key = (model_hospital, test_hospital)\n",
    "        test_df = hospital_df_dict[test_hospital + '_test'].copy()\n",
    "        test_df[continuous_features] = scaler.transform(test_df[continuous_features])\n",
    "\n",
    "        test_X = test_df[continuous_features + discrete_features].values\n",
    "        test_y = test_df.label.values\n",
    "        \n",
    "        # predict on test_X\n",
    "        test_preds = model.predict_proba(test_X)[:, -1]\n",
    "        hospital_test_preds[key] = test_preds\n",
    "        \n",
    "        baseline_test_preds = baseline_model.predict_proba(test_df[baseline_features].values)[:, -1]\n",
    "        hospital_baseline_test_preds[key] = baseline_test_preds\n",
    "        \n",
    "        # track performance\n",
    "        auroc_dict[key] = roc_auc_score(test_y, test_preds)\n",
    "        auprc_dict[key] = average_precision_score(test_y, test_preds)\n",
    "        \n",
    "        auroc_baseline_dict[key] = roc_auc_score(test_y, baseline_test_preds)\n",
    "        auprc_baseline_dict[key] = average_precision_score(test_y, baseline_test_preds)\n",
    "    \n",
    "    print(\"Done processing {}\".format(model_hospital))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_baseline_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick a source hospital and collect predictions on pooled test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp = 'hospital_hcgh' # worst transfer\n",
    "scaler = hospital_scalers[hosp]\n",
    "\n",
    "hcgh_test_dfs = []\n",
    "\n",
    "for test_hospital in hospital_ids:\n",
    "    test_df = hospital_df_dict[test_hospital + '_test'].copy()\n",
    "    test_df[continuous_features] = scaler.transform(test_df[continuous_features])\n",
    "    \n",
    "    test_df['aam_prediction'] = hospital_test_preds[(hosp, test_hospital)]\n",
    "    \n",
    "    test_df['baseline_prediction'] = hospital_baseline_test_preds[(hosp, test_hospital)]\n",
    "    \n",
    "    hcgh_test_dfs.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcgh_combined_test_df = pd.concat(hcgh_test_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hcgh_combined_test_df.to_hdf('/data/adarsh/fda_project_data/hcgh_combined_test_df_7_11_2022.h5', key='s', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcgh_combined_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFISP step 3: Retraining Diagnostic [Run after afisp notebook]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Size diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = hospital_df_dict['hospital_hcgh_train'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostic1_results(rule, num_points=5, n_trials=10):\n",
    "    con_df = pd.concat([hospital_df_dict[x + '_train'] for x in ['hospital_bmc',\n",
    "     'hospital_jhh',\n",
    "     'hospital_smh',\n",
    "     'hospital_sh']])\n",
    "    \n",
    "    con_df = pd.concat([hospital_df_dict[x + '_train'] for x in hospital_ids])\n",
    "    \n",
    "    merged_df = con_df.merge(commorbidity_df, on ='enc_id', how='left')\n",
    "    \n",
    "    \n",
    "    init_n = merged_df.query('hospital_hcgh == 1').query(rule).shape[0]\n",
    "\n",
    "    diag_df = merged_df.query(rule)\n",
    "    \n",
    "    max_n = diag_df.shape[0] - 1\n",
    "    \n",
    "    # training size grid\n",
    "    # data_amounts=np.round(np.exp(np.linspace(np.log(1), np.log(max_n), num_points))).astype(int)\n",
    "    data_amounts = np.round(np.linspace(50, max_n, num=num_points)).astype(int)\n",
    "    print(data_amounts, init_n, max_n)\n",
    "    \n",
    "    # data_amounts = [0, 100, 500, 1000, 1500, 2000, 2500, 3179]\n",
    "\n",
    "    diagnostic_models = {}\n",
    "    diagnostic_test_preds = {}\n",
    "    \n",
    "    # train model\n",
    "    scaler = hospital_scalers['hospital_hcgh']\n",
    "    diag_test_df = hcgh_combined_test_df.merge(commorbidity_df, on ='enc_id', how='left')\n",
    "\n",
    "    result_aucs = {}\n",
    "    result_sub_aucs = {}\n",
    "    result_sub_aucs_lower = {}\n",
    "    result_sub_aucs_upper = {}\n",
    "    result_full_aucs_lower = {}\n",
    "    result_full_aucs_upper = {}\n",
    "    for amt in data_amounts:\n",
    "        \n",
    "        preds_by_train_amount = np.zeros((n_trials, hcgh_combined_test_df.shape[0]))\n",
    "        \n",
    "        for trial in range(n_trials):\n",
    "            train_df = hospital_df_dict['hospital_hcgh' + '_train'].copy()\n",
    "            # ignore rows corresonding to the rule\n",
    "            \n",
    "            train_df = train_df[~train_df.merge(commorbidity_df, on ='enc_id', how='left').eval(rule).values]\n",
    "\n",
    "            train_df[continuous_features] = scaler.transform(train_df[continuous_features])\n",
    "\n",
    "            if amt > 0:\n",
    "                # sample rows from the subgroup\n",
    "                sample = diag_df.sample(n=amt)\n",
    "                sample[continuous_features] = scaler.transform(sample[continuous_features])\n",
    "                train_df = pd.concat([train_df, sample])\n",
    "            train_X = train_df[continuous_features + discrete_features].values\n",
    "            train_y = train_df.label.values\n",
    "\n",
    "       \n",
    "            lgbm = LogisticRegression(random_state=1234, n_jobs=-1, C=1e3)\n",
    "            lgbm.fit(train_X, train_y)\n",
    "            diagnostic_models[amt] = lgbm\n",
    "\n",
    "\n",
    "            model_hospital = 'hospital_hcgh'\n",
    "            collect_test_preds = []\n",
    "            for test_hospital in hospital_ids:\n",
    "\n",
    "                key = (amt, test_hospital)\n",
    "                test_df = hospital_df_dict[test_hospital + '_test'].copy()\n",
    "                test_df[continuous_features] = scaler.transform(test_df[continuous_features])\n",
    "\n",
    "                test_X = test_df[continuous_features + discrete_features].values\n",
    "                test_y = test_df.label.values\n",
    "\n",
    "                # predict on test_X\n",
    "                test_preds = lgbm.predict_proba(test_X)[:, -1]\n",
    "                collect_test_preds += list(test_preds)\n",
    "                \n",
    "            preds_by_train_amount[trial] = np.array(collect_test_preds)\n",
    "        # finished training n_trials times\n",
    "        \n",
    "        full_aucs = np.array([roc_auc_score(diag_test_df.label, preds_by_train_amount[i]) for i in range(n_trials)])\n",
    "        inds = np.array(diag_test_df.query(rule).index)\n",
    "        sub_aucs = np.array([roc_auc_score(diag_test_df.label.values[inds], preds_by_train_amount[i][inds]) for i in range(n_trials)])\n",
    "                \n",
    "        result_aucs[amt] = np.mean(full_aucs)\n",
    "        result_sub_aucs[amt] = np.mean(sub_aucs)\n",
    "        result_sub_aucs_lower[amt] = np.percentile(sub_aucs, 2.5)\n",
    "        result_sub_aucs_upper[amt] = np.percentile(sub_aucs, 97.5)\n",
    "        result_full_aucs_lower[amt] = np.percentile(full_aucs, 2.5)\n",
    "        result_full_aucs_upper[amt] = np.percentile(full_aucs, 97.5)\n",
    "        print(\"N = {}, Full AUC = {:.3f}, Sub AUC = {:.3f}\".format(amt, result_aucs[amt], result_sub_aucs[amt]))\n",
    " \n",
    "    return diag_test_df, data_amounts, init_n, result_aucs, result_sub_aucs, result_sub_aucs_lower, result_sub_aucs_upper, result_full_aucs_lower, result_full_aucs_upper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = \"anemia == 1 and nonspecific_lung_disease >= 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_test_df, data_amounts, init_n, full_aucs, sub_aucs, sub_lower, sub_upper, full_lower, full_upper = get_diagnostic1_results(rule, n_trials=10, num_points=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_test_df, data_amounts, init_n, full_aucs, sub_aucs, sub_lower, sub_upper, full_lower, full_upper = get_diagnostic1_results(rule, n_trials=10, num_points=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_amounts, list(full_aucs.values()), '--.')\n",
    "plt.fill_between(data_amounts, list(full_lower.values()), list(full_upper.values()), alpha=0.25)\n",
    "\n",
    "plt.ylabel('Full Population AUROC')\n",
    "plt.xlabel('Subgroup # of Training Examples')\n",
    "plt.axvline(x=init_n, ls='--', color='#fb8072', label='Original # of Training Samples')\n",
    "plt.axhline(y=0.986, ls='--', color='#b3de69', label='Original Full Population AUROC')\n",
    "plt.xlim(0, 2500)\n",
    "plt.legend()\n",
    "plt.savefig('figs/pub_fullgroup_perf_anemia_lung_disease.pdf', dpi=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_amounts, list(sub_aucs.values()), '--.')\n",
    "plt.fill_between(data_amounts, list(sub_lower.values()), list(sub_upper.values()), alpha=0.25)\n",
    "plt.ylabel('Subgroup AUROC')\n",
    "plt.xlabel('Subgroup # of Training Examples')\n",
    "plt.axvline(x=init_n, ls='--', color='#fb8072', label='Original # of Training Samples')\n",
    "plt.xlim(0, 2500)\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('figs/pub_subgroup_perf_anemia_lung_disease.pdf', dpi=360)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
