{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = pd.read_csv(\"/data/adarsh/fda_project_data/study_cohort_with_outcome_truncated_15days.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('/data/deidentified_trews_deployment_data/cdm/cdm_t.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_enc_ids = cohort.enc_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dask default scheduling\n",
    "start = time.time()\n",
    "\n",
    "# find all rows in cdm_t that have an enc_id in our patient cohort\n",
    "cdm_t = df.loc[df.enc_id.isin(cohort_enc_ids)].compute()\n",
    "\n",
    "end = time.time()\n",
    "print((end-start)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cdm_t.fid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting lab test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to extract lab tests, vital signs, composite indices, and administrative info\n",
    "# start with lab tests: most recent value in the last 72 hours\n",
    "lab_vars = ['anion_gap', 'bicarbonate', 'glucose', 'hematocrit', 'lactate', 'bun', 'creatinine', 'sodium',\n",
    "            'troponin', 'wbc']\n",
    "\n",
    "lab_df = cdm_t.loc[cdm_t.fid.isin(lab_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df['tsp'] = pd.to_datetime(lab_df.tsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df = lab_df.merge(cohort[['enc_id', 'admit_time', 'end_time', 'hospital']], on='enc_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df['admit_time'] = pd.to_datetime(lab_df['admit_time'])\n",
    "lab_df['end_time'] = pd.to_datetime(lab_df['end_time'])\n",
    "\n",
    "# only interested in lab measurements taken before the last observation time\n",
    "lab_df = lab_df.query('tsp <= end_time')\n",
    "lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hourly prediction intervals\n",
    "cohort['obs_time'] = cohort.apply(lambda x: pd.date_range(x['admit_time'], x['end_time'], freq=\"1H\"),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime_index_to_rows(row):\n",
    "    frame = row.obs_time.to_frame().reset_index().rename(columns={'index':'enc_id', 0:'obs_time'})\n",
    "    frame['enc_id'] = row['enc_id']\n",
    "    \n",
    "    return frame\n",
    "\n",
    "pred_df = pd.concat(list(cohort.apply(convert_datetime_index_to_rows, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.sort_values(['enc_id', 'obs_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract lab measurements\n",
    "\n",
    "for var in lab_vars:\n",
    "    # get the lab value rows, sort them, and combine them with the prediction times\n",
    "    temp_df = lab_df.query('fid == @var').sort_values(['enc_id', 'tsp']).merge(pred_df, on='enc_id', how='inner')\n",
    "    # only care about values before prediction time\n",
    "    temp_df = temp_df.query('tsp <= obs_time')\n",
    "    temp_df['elapsed_time'] = temp_df['obs_time'] - temp_df['tsp']\n",
    "    # get most recent (i.e., last) value that occurred in the preceding 72 hours\n",
    "    temp_values = (temp_df\n",
    "                   .loc[temp_df.elapsed_time <= datetime.timedelta(hours=72)]\n",
    "                   .groupby(['enc_id', 'obs_time'], as_index=False)\n",
    "                   .nth(-1)\n",
    "                   .reset_index())\n",
    "    temp_values = temp_values[['enc_id', 'obs_time', 'value']].rename(columns={'value':var})\n",
    "    \n",
    "    # merge into the pred df\n",
    "    pred_df = pred_df.merge(temp_values, on=['enc_id', 'obs_time'], how=\"left\")\n",
    "    \n",
    "    print(\"Completed extraction of {}\".format(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missingness percentages\n",
    "for var in lab_vars:\n",
    "    print(var, np.mean(pred_df[var].isnull().astype(np.double)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add troponin missingness indicator\n",
    "# will add other missingness indicators for posterity\n",
    "# indicator is 1 if lab test is missing\n",
    "for var in lab_vars:\n",
    "    pred_df[var + \"_missing\"] = pred_df[var].isnull().astype(np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our work so far\n",
    "# pred_df.to_csv(\"/data/adarsh/fda_project_data/lab_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract vital signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pred_df[['enc_id', 'obs_time', 'anion_gap', 'bicarbonate', 'glucose',\n",
    "#        'hematocrit', 'lactate', 'bun', 'creatinine', 'sodium', 'troponin',\n",
    "#        'wbc', 'anion_gap_missing', 'bicarbonate_missing', 'glucose_missing',\n",
    "#        'hematocrit_missing', 'lactate_missing', 'bun_missing',\n",
    "#        'creatinine_missing', 'sodium_missing', 'troponin_missing',\n",
    "#        'wbc_missing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital_vars = ['nbp_dias', 'nbp_sys', 'heart_rate', 'spo2', 'resp_rate', 'temperature', 'gcs']\n",
    "# not included :(Anion gap รท serum bicarbonate) ร 1000 (computed from extracted lab tests)\n",
    "# not included: shock index (latest heart rate / latest systolic bp); computed from extracted vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital_df = cdm_t.loc[cdm_t.fid.isin(vital_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital_df['tsp'] = pd.to_datetime(vital_df.tsp)\n",
    "vital_df = vital_df.merge(cohort[['enc_id', 'admit_time', 'end_time', 'hospital']], on='enc_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital_df['admit_time'] = pd.to_datetime(vital_df['admit_time'])\n",
    "vital_df['end_time'] = pd.to_datetime(vital_df['end_time'])\n",
    "\n",
    "# only interested in vital measurements taken before the last observation time\n",
    "vital_df = vital_df.query('tsp <= end_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract vital measurements\n",
    "\n",
    "for var in vital_vars:\n",
    "    # get the vital value rows, sort them, and combine them with the prediction times\n",
    "    temp_df = (vital_df\n",
    "               .query('fid == @var')\n",
    "               .sort_values(['enc_id', 'tsp'])\n",
    "               .merge(pred_df[['enc_id', 'obs_time']], on='enc_id', how='inner'))\n",
    "    \n",
    "    # only care about values before prediction time\n",
    "    temp_df = temp_df.query('tsp <= obs_time')\n",
    "    temp_df['elapsed_time'] = temp_df['obs_time'] - temp_df['tsp']\n",
    "    \n",
    "    # only care about values in the last 24 hours\n",
    "    temp_df = temp_df.loc[temp_df.elapsed_time <= datetime.timedelta(hours=24)]\n",
    "    temp_df['value'] = temp_df['value'].astype(np.double)\n",
    "    \n",
    "    # filter out values according to AAM paper\n",
    "    reference_val = None\n",
    "    if var == 'nbp_sys':\n",
    "        temp_df = temp_df.loc[temp_df['value'] <= 300]\n",
    "        reference_val = 100\n",
    "    elif var == 'nbp_dias':\n",
    "        reference_val = 70\n",
    "    elif var == 'heart_rate':\n",
    "        temp_df = temp_df.loc[temp_df['value'] <= 300]\n",
    "        reference_val = 75\n",
    "    elif var == 'resp_rate':\n",
    "        temp_df = temp_df.loc[temp_df['value'] <= 80]\n",
    "        reference_val = 11\n",
    "    elif var == 'spo2':\n",
    "        temp_df = temp_df.loc[temp_df['value'] >= 50]\n",
    "        reference_val = 100\n",
    "    elif var == 'temperature':\n",
    "        temp_df = temp_df.loc[(temp_df['value'] >= 85) & (temp_df['value'] <= 108)]\n",
    "        reference_val = 98\n",
    "    elif var == 'gcs':\n",
    "        # best possible gcs is 15, so interested in lowest value (i.e. farthest from 15)\n",
    "        reference_val = 15\n",
    "    \n",
    "    \n",
    "    # get the highest value in the preceding 24 hours\n",
    "    highest_values = (temp_df\n",
    "                      .groupby(['enc_id', 'obs_time'], as_index=False)['value']\n",
    "                      .max())\n",
    "    highest_values = highest_values.rename(columns={'value':var + '_high'})\n",
    "    # get the lowest value in the preceding 24 hours\n",
    "    lowest_values = (temp_df\n",
    "                     .groupby(['enc_id', 'obs_time'], as_index=False)['value']\n",
    "                     .min())\n",
    "    highest_values[var+'_low'] = lowest_values['value']\n",
    "    \n",
    "    # get the most \"deranged\" value in the preceding 24 hours\n",
    "    highest_values['high_dev'] = np.abs(highest_values[var+'_high'] - reference_val)\n",
    "    highest_values['low_dev'] = np.abs(highest_values[var+'_low'] - reference_val)\n",
    "    # if highest is more extreme then pick highest\n",
    "    highest_values[var+'_worst'] = (highest_values['high_dev'] > highest_values['low_dev'])*highest_values[var+'_high']\n",
    "    # if lowest is more extreme then pick lowest\n",
    "    highest_values[var+'_worst'] = highest_values[var+'_worst'] + (highest_values['low_dev'] >= highest_values['high_dev'])*highest_values[var+'_low']\n",
    "        \n",
    "    # get latest value\n",
    "    # get most recent (i.e., last) value that occurred in the preceding 24 hours\n",
    "    latest_values = (temp_df\n",
    "                     .groupby(['enc_id', 'obs_time'], as_index=False)['value']\n",
    "                     .nth(-1)\n",
    "                     .values)\n",
    "    highest_values[var+'_latest'] = latest_values\n",
    "    \n",
    "    highest_values = highest_values[['enc_id', 'obs_time', var+'_high', var+'_low', var+'_worst', var+'_latest']]\n",
    "       \n",
    "    \n",
    "    # merge into the pred df\n",
    "    pred_df = pred_df.merge(highest_values, on=['enc_id', 'obs_time'], how=\"left\")\n",
    "    \n",
    "    print(\"Completed extraction of {}\".format(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df.to_hdf('/data/adarsh/fda_project_data/lab_and_features.h5', key='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# season, time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_months = pd.DatetimeIndex(pred_df.obs_time).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_season_map = {\n",
    "    1:1,\n",
    "    2:1,\n",
    "    11:1,\n",
    "    12:1,\n",
    "    3:2,\n",
    "    4:2,\n",
    "    5:2,\n",
    "    6:2,\n",
    "    7:3,\n",
    "    8:3,\n",
    "    9:3,\n",
    "    10:3\n",
    "}\n",
    "\n",
    "pred_df['season'] = extracted_months.map(month_to_season_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_to_timeframe_map = {}\n",
    "for i in range(24):\n",
    "    if i in range(1,7):\n",
    "        hour_to_timeframe_map[i] = 1\n",
    "    elif i in range(7,12):\n",
    "        hour_to_timeframe_map[i] = 2\n",
    "    else:\n",
    "        hour_to_timeframe_map[i] = 3\n",
    "\n",
    "pred_df['time_of_day'] = pd.DatetimeIndex(pred_df.obs_time).hour.map(hour_to_timeframe_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in lab_vars:\n",
    "    pred_df[var] = pred_df[var].astype(np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_hdf('/data/adarsh/fda_project_data/aam_lab_and_vital_features_with_spo2.h5', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.enc_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
